"""
AOI ç³»çµ±æ•´åˆç¯„ä¾‹
Integration Example with AOI System

å±•ç¤ºå¦‚ä½•å°‡æ—‹è½‰è§’åº¦æª¢æ¸¬æ•´åˆåˆ°ç¾æœ‰çš„ AOI ç³»çµ±
"""

import numpy as np
import cv2
from typing import Dict, Tuple, Optional


class RotationDetector:
    """æ—‹è½‰è§’åº¦æª¢æ¸¬å™¨é¡åˆ¥"""

    def __init__(self, method='minAreaRect'):
        """
        åˆå§‹åŒ–æª¢æ¸¬å™¨

        Args:
            method: æª¢æ¸¬æ–¹æ³• ('minAreaRect', 'pca', 'markers')
        """
        self.method = method

    def detect(self, image: np.ndarray, bbox: Optional[Dict] = None) -> Dict:
        """
        æª¢æ¸¬ç‰©ä»¶æ—‹è½‰è§’åº¦

        Args:
            image: è¼¸å…¥å½±åƒ
            bbox: ç‰©ä»¶é‚Šç•Œæ¡† {'x1', 'y1', 'x2', 'y2'}ï¼ˆå¯é¸ï¼‰

        Returns:
            çµæœå­—å…¸ï¼š{
                'angle': æ—‹è½‰è§’åº¦,
                'center': ä¸­å¿ƒåº§æ¨™,
                'success': æ˜¯å¦æˆåŠŸ
            }
        """
        # å¦‚æœæœ‰ bboxï¼Œè£åˆ‡å½±åƒ
        if bbox:
            x1, y1 = bbox['x1'], bbox['y1']
            x2, y2 = bbox['x2'], bbox['y2']
            roi = image[y1:y2, x1:x2]
            offset = (x1, y1)
        else:
            roi = image
            offset = (0, 0)

        # è½‰ç‚ºç°éš
        if len(roi.shape) == 3:
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        else:
            gray = roi

        # äºŒå€¼åŒ–
        _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)

        # å°‹æ‰¾è¼ªå»“
        contours, _ = cv2.findContours(
            binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )

        if len(contours) == 0:
            return {'success': False, 'angle': 0, 'center': (0, 0)}

        # å–æœ€å¤§è¼ªå»“
        largest_contour = max(contours, key=cv2.contourArea)

        # æ ¹æ“šæ–¹æ³•æª¢æ¸¬è§’åº¦
        if self.method == 'minAreaRect':
            angle, center = self._detect_with_min_area_rect(largest_contour)
        elif self.method == 'pca':
            angle, center = self._detect_with_pca(largest_contour)
        else:
            return {'success': False, 'angle': 0, 'center': (0, 0)}

        # åŠ ä¸Šåç§»
        center = (center[0] + offset[0], center[1] + offset[1])

        return {
            'success': True,
            'angle': angle,
            'center': center,
            'method': self.method
        }

    def _detect_with_min_area_rect(self, contour) -> Tuple[float, Tuple[int, int]]:
        """ä½¿ç”¨æœ€å°é¢ç©çŸ©å½¢æª¢æ¸¬"""
        rect = cv2.minAreaRect(contour)
        center, size, angle = rect

        # è§’åº¦æ­£è¦åŒ–
        if size[0] < size[1]:
            angle = angle + 90

        return angle, (int(center[0]), int(center[1]))

    def _detect_with_pca(self, contour) -> Tuple[float, Tuple[int, int]]:
        """ä½¿ç”¨ PCA æª¢æ¸¬"""
        # è¨ˆç®—è³ªå¿ƒ
        M = cv2.moments(contour)
        if M["m00"] == 0:
            return 0, (0, 0)

        cx = int(M["m10"] / M["m00"])
        cy = int(M["m01"] / M["m00"])

        # PCA
        pts = contour.reshape(-1, 2).astype(np.float32)
        mean, eigenvectors = cv2.PCACompute(pts, mean=None)
        main_direction = eigenvectors[0]

        # è¨ˆç®—è§’åº¦
        angle = np.degrees(np.arctan2(main_direction[1], main_direction[0]))
        if angle < 0:
            angle += 360

        return angle, (cx, cy)


class AOIWithRotation:
    """
    æ•´åˆæ—‹è½‰æª¢æ¸¬çš„ AOI ç³»çµ±
    æ¨¡æ“¬èˆ‡å¾Œç«¯ API çš„æ•´åˆ
    """

    def __init__(self):
        self.rotation_detector = RotationDetector(method='minAreaRect')

    def inspect_and_pick(self, image: np.ndarray, defect_threshold: float = 0.5):
        """
        æª¢æ¸¬ç‘•ç–µä¸¦è¨ˆç®—æŠ“å–è³‡è¨Š

        Args:
            image: è¼¸å…¥å½±åƒ
            defect_threshold: ç‘•ç–µé–¾å€¼

        Returns:
            æª¢æ¸¬çµæœå’ŒæŠ“å–æŒ‡ä»¤
        """
        results = {
            'inspection': None,
            'pick_command': None
        }

        # 1. AOI æª¢æ¸¬ï¼ˆæ¨¡æ“¬ï¼‰
        inspection_result = self._simulate_aoi_inspection(image)
        results['inspection'] = inspection_result

        # 2. å¦‚æœéœ€è¦æŠ“å–ï¼Œè¨ˆç®—æ—‹è½‰è§’åº¦
        if inspection_result['needs_removal']:
            rotation_info = self.rotation_detector.detect(
                image,
                bbox=inspection_result['bbox']
            )

            if rotation_info['success']:
                # 3. ç”Ÿæˆæ©Ÿå™¨äººæŒ‡ä»¤
                pick_command = self._generate_pick_command(
                    rotation_info,
                    inspection_result
                )
                results['pick_command'] = pick_command

        return results

    def _simulate_aoi_inspection(self, image: np.ndarray) -> Dict:
        """æ¨¡æ“¬ AOI æª¢æ¸¬"""
        # é€™è£¡æ¨¡æ“¬æª¢æ¸¬çµæœ
        # å¯¦éš›æ‡‰ç”¨ä¸­æœƒå‘¼å«çœŸå¯¦çš„ AOI æª¢æ¸¬æ¨¡çµ„

        # å°‹æ‰¾ç‰©ä»¶
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
        contours, _ = cv2.findContours(
            binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )

        if len(contours) == 0:
            return {'needs_removal': False}

        largest = max(contours, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(largest)

        # æ¨¡æ“¬ç‘•ç–µæª¢æ¸¬
        defect_score = np.random.random()

        return {
            'needs_removal': defect_score > 0.3,  # 70% éœ€è¦ç§»é™¤
            'defect_score': defect_score,
            'defect_type': 'NG' if defect_score > 0.5 else 'PASS',
            'bbox': {'x1': x, 'y1': y, 'x2': x+w, 'y2': y+h}
        }

    def _generate_pick_command(
        self,
        rotation_info: Dict,
        inspection_result: Dict
    ) -> Dict:
        """
        ç”Ÿæˆæ©Ÿå™¨äººæŠ“å–æŒ‡ä»¤

        Args:
            rotation_info: æ—‹è½‰è³‡è¨Š
            inspection_result: æª¢æ¸¬çµæœ

        Returns:
            æ©Ÿå™¨äººæŒ‡ä»¤
        """
        center = rotation_info['center']
        angle = rotation_info['angle']

        # åº§æ¨™è½‰æ›ï¼ˆåƒç´  -> æ©Ÿå™¨äººåº§æ¨™ï¼‰
        # å‡è¨­ï¼šç›¸æ©Ÿè¦–é‡ä¸­å¿ƒ = æ©Ÿå™¨äººåŸé»
        # å¯¦éš›éœ€è¦ç›¸æ©Ÿæ¨™å®š
        PIXEL_TO_MM = 0.1
        IMAGE_CENTER_X = 250  # å‡è¨­å½±åƒä¸­å¿ƒ
        IMAGE_CENTER_Y = 250

        robot_x = (center[0] - IMAGE_CENTER_X) * PIXEL_TO_MM
        robot_y = (IMAGE_CENTER_Y - center[1]) * PIXEL_TO_MM

        # æ±ºå®šæ”¾ç½®ä½ç½®ï¼ˆæ ¹æ“šæª¢æ¸¬çµæœï¼‰
        if inspection_result['defect_type'] == 'NG':
            place_x, place_y = 100.0, 100.0  # NG å€
            bin_type = 'NG'
        else:
            place_x, place_y = -100.0, 100.0  # PASS å€
            bin_type = 'PASS'

        command = {
            'action': 'pick_and_place',
            'pick_position': {
                'x': robot_x,
                'y': robot_y,
                'z': 0.0,
                'rotation': angle
            },
            'place_position': {
                'x': place_x,
                'y': place_y,
                'z': 0.0,
                'rotation': 0.0
            },
            'gripper_rotation': angle,
            'bin_type': bin_type,
            'defect_score': inspection_result['defect_score']
        }

        return command


# ============================================
# ä½¿ç”¨ç¯„ä¾‹
# ============================================

def demo_integration():
    """ç¤ºç¯„æ•´åˆä½¿ç”¨"""
    print("=" * 60)
    print("AOI ç³»çµ±æ•´åˆç¯„ä¾‹")
    print("=" * 60)

    # å‰µå»ºæ¸¬è©¦å½±åƒï¼ˆæ—‹è½‰çš„çŸ©å½¢ï¼‰
    img = np.zeros((500, 500, 3), dtype=np.uint8)
    img[:] = (200, 200, 200)  # ç°è‰²èƒŒæ™¯

    # å‰µå»ºæ—‹è½‰ç‰©ä»¶
    angle = 42.0
    center = (250, 250)
    size = (120, 80)
    rect = (center, size, angle)
    box = cv2.boxPoints(rect)
    box = np.int0(box)
    cv2.drawContours(img, [box], 0, (100, 150, 200), -1)

    # åˆå§‹åŒ–ç³»çµ±
    aoi_system = AOIWithRotation()

    # åŸ·è¡Œæª¢æ¸¬å’Œç”ŸæˆæŒ‡ä»¤
    print("\nåŸ·è¡Œæª¢æ¸¬...")
    results = aoi_system.inspect_and_pick(img)

    # é¡¯ç¤ºçµæœ
    print("\næª¢æ¸¬çµæœï¼š")
    print(f"  ç‘•ç–µåˆ†æ•¸ï¼š{results['inspection']['defect_score']:.3f}")
    print(f"  åˆ¤å®šï¼š{results['inspection']['defect_type']}")
    print(f"  éœ€è¦ç§»é™¤ï¼š{results['inspection']['needs_removal']}")

    if results['pick_command']:
        print("\nğŸ¤– æ©Ÿå™¨äººæŒ‡ä»¤ï¼š")
        cmd = results['pick_command']
        print(f"  å‹•ä½œï¼š{cmd['action']}")
        print(f"  æŠ“å–ä½ç½®ï¼š")
        print(f"    X = {cmd['pick_position']['x']:7.2f} mm")
        print(f"    Y = {cmd['pick_position']['y']:7.2f} mm")
        print(f"    æ—‹è½‰ = {cmd['pick_position']['rotation']:6.2f}Â°")
        print(f"  æ”¾ç½®ä½ç½®ï¼š{cmd['bin_type']} å€")
        print(f"    X = {cmd['place_position']['x']:7.2f} mm")
        print(f"    Y = {cmd['place_position']['y']:7.2f} mm")

    # è¦–è¦ºåŒ–
    result_img = img.copy()

    # ç¹ªè£½æª¢æ¸¬æ¡†
    bbox = results['inspection']['bbox']
    cv2.rectangle(result_img,
                 (bbox['x1'], bbox['y1']),
                 (bbox['x2'], bbox['y2']),
                 (0, 255, 0), 2)

    if results['pick_command']:
        # ç¹ªè£½æŠ“å–é»å’Œè§’åº¦
        pick_pos = results['pick_command']['pick_position']
        cx, cy = center

        # ç¹ªè£½è§’åº¦æŒ‡ç¤º
        angle_rad = np.radians(pick_pos['rotation'])
        arrow_len = 60
        end_x = int(cx + arrow_len * np.cos(angle_rad))
        end_y = int(cy + arrow_len * np.sin(angle_rad))

        cv2.circle(result_img, (cx, cy), 5, (0, 0, 255), -1)
        cv2.arrowedLine(result_img, (cx, cy), (end_x, end_y),
                       (255, 0, 0), 2, tipLength=0.3)

        # é¡¯ç¤ºè³‡è¨Š
        cv2.putText(result_img, f"{pick_pos['rotation']:.1f} deg",
                   (cx + 10, cy - 10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

        cv2.putText(result_img, results['inspection']['defect_type'],
                   (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    cv2.imshow('AOI + Rotation Detection', result_img)
    print("\næŒ‰ä»»æ„éµé—œé–‰è¦–çª—...")
    cv2.waitKey(0)
    cv2.destroyAllWindows()

    print("\nâœ… ç¤ºç¯„å®Œæˆï¼")


# ============================================
# Flask API ç«¯é»ç¯„ä¾‹
# ============================================

def flask_api_example():
    """
    Flask API æ•´åˆç¯„ä¾‹ä»£ç¢¼
    å¯ä»¥åŠ åˆ° aoi-system/backend/app/routes/ ä¸­
    """
    example_code = """
# aoi-system/backend/app/routes/rotation_detection.py

from flask import Blueprint, request, jsonify
import cv2
import numpy as np
from app.services.rotation_detector import RotationDetector

rotation_bp = Blueprint('rotation', __name__)
detector = RotationDetector(method='minAreaRect')

@rotation_bp.route('/api/detect_rotation', methods=['POST'])
def detect_rotation():
    '''æª¢æ¸¬ç‰©ä»¶æ—‹è½‰è§’åº¦'''

    # æ¥æ”¶å½±åƒ
    file = request.files.get('image')
    if not file:
        return jsonify({'error': 'No image provided'}), 400

    # è®€å–å½±åƒ
    image_bytes = file.read()
    nparr = np.frombuffer(image_bytes, np.uint8)
    image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

    # æª¢æ¸¬æ—‹è½‰è§’åº¦
    result = detector.detect(image)

    if result['success']:
        return jsonify({
            'success': True,
            'angle': result['angle'],
            'center': result['center'],
            'method': result['method']
        })
    else:
        return jsonify({
            'success': False,
            'error': 'Detection failed'
        }), 400

@rotation_bp.route('/api/inspect_with_rotation', methods=['POST'])
def inspect_with_rotation():
    '''AOI æª¢æ¸¬ + æ—‹è½‰è§’åº¦'''

    file = request.files.get('image')
    if not file:
        return jsonify({'error': 'No image provided'}), 400

    # è®€å–å½±åƒ
    image_bytes = file.read()
    nparr = np.frombuffer(image_bytes, np.uint8)
    image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

    # åŸ·è¡Œå®Œæ•´æª¢æ¸¬
    aoi_system = AOIWithRotation()
    results = aoi_system.inspect_and_pick(image)

    return jsonify(results)
"""
    print("\n" + "=" * 60)
    print("Flask API æ•´åˆç¯„ä¾‹")
    print("=" * 60)
    print(example_code)


if __name__ == "__main__":
    print("ğŸ¯ AOI ç³»çµ±æ•´åˆç¯„ä¾‹\n")

    # åŸ·è¡Œç¤ºç¯„
    demo_integration()

    # é¡¯ç¤º API ç¯„ä¾‹
    flask_api_example()

    print("\n" + "=" * 60)
    print("æ•´åˆèªªæ˜")
    print("=" * 60)
    print("""
    å¦‚ä½•æ•´åˆåˆ°ç¾æœ‰ç³»çµ±ï¼š

    1. å°‡ RotationDetector é¡åˆ¥åŠ å…¥åˆ°å¾Œç«¯æœå‹™
       æª”æ¡ˆï¼šaoi-system/backend/app/services/rotation_detector.py

    2. å»ºç«‹ API ç«¯é»
       æª”æ¡ˆï¼šaoi-system/backend/app/routes/rotation_detection.py

    3. å‰ç«¯å‘¼å« API
       åœ¨ aoi-system/frontend/src/services/api.ts ä¸­åŠ å…¥ï¼š

       export const detectRotation = async (imageFile: File) => {
         const formData = new FormData();
         formData.append('image', imageFile);

         const response = await fetch('/api/detect_rotation', {
           method: 'POST',
           body: formData
         });

         return response.json();
       };

    4. æ›´æ–°æ©Ÿæ¢°æ‰‹è‡‚æ¨¡æ“¬å™¨
       åœ¨ RoboticArmSimulator.tsx ä¸­ä½¿ç”¨æ—‹è½‰è§’åº¦è³‡è¨Š
    """)
